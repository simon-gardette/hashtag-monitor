{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "hashtag = \"minecraft\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import os\n",
    "import json\n",
    "from IPython.display import JSON\n",
    "import logging\n",
    "import parser\n",
    "import traceback\n",
    "import sys\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, MetaData, Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def get_keywords():\n",
    "    Base = automap_base()\n",
    "\n",
    "    # engine, suppose it has two tables 'user' and 'address' set up\n",
    "    engine = create_engine(os.environ['SHARED_DB_URI'])\n",
    "\n",
    "    # reflect the tables\n",
    "    Base.prepare(engine, reflect=True)\n",
    "\n",
    "    # mapped classes are now created with names by default\n",
    "    # matching that of the table name.\n",
    "\n",
    "    raws = Base.classes.raws\n",
    "    keywords = Base.classes.keywords\n",
    "\n",
    "    session = Session(engine)\n",
    "\n",
    "    keywords = session.query(keywords).all()\n",
    "    \n",
    "    return keyword\n",
    "\n",
    "    for keyword in keywords:\n",
    "        recordObject = {'id': keyword.id,\n",
    "                        'keyword_name': keyword.keyword_name,\n",
    "                        'brand_id': keyword.brand_id}\n",
    "        print(recordObject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Oauth handling (probably should do a class later). Shouldalso use an generator for secret and key but as twitter doesn't expire it it will do for the moment. \n",
    "In a production version I would probably generate an app by account so I can track each account usage. \n",
    "\n",
    "Oauth 2 could also psossibly be a solution as I only need public infos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "consumer_key = os.environ['TWITTER_API_KEY']\n",
    "consumer_secret = os.environ['TWITTER_API_SECRET']\n",
    "key = os.environ['TWITTER_ACCESS_TOKEN']\n",
    "secret = os.environ['TWITTER_ACCESS_SECRET']\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(key, secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# using tweepy \n",
    "The main objective is to gather infos from twitter. We're gonna use the stream endpoint because using the search doesn't return all the tweets.\n",
    "\n",
    "Probably end up bumping into api limitations pretty fast but it will be ok for the demo.\n",
    "\n",
    "The process will be the following : \n",
    "\n",
    "- Get latest tweet \n",
    "- Store Raw response (probably in an S3/minio bucket. will probably do it in second time but it should be a good idea in case the processing crashes\n",
    "- get relevant datas\n",
    "- run additional infos gathering and transform \n",
    "      - detect mood ? \n",
    "      - lang detection ? \n",
    "      - ...\n",
    "- store in the sql base (shared) \n",
    "\n",
    "Airflow process : \n",
    "- Each hour detect new keywords. \n",
    "- For each keyord create a notebook (aka a thread) \n",
    "- Check if all notebook Running. \n",
    "- can mark a keyword as inactive in Flask then  don't check \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set up our main class using tweepy.StreamListener\n",
    "class TwitterListener(tweepy.StreamListener):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.database = os.environ['SHARED_DB_URI']\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            # returning False in on_data disconnects the stream\n",
    "            return False\n",
    "\n",
    "    def on_status(self, status):\n",
    "        print(status.text)\n",
    "        return True\n",
    "\n",
    "    def on_data(self, data):\n",
    "        \"\"\"\n",
    "        Automatic detection of the kind of data collected from Twitter\n",
    "        This method reads in tweet data as JSON and extracts the data we want.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # parse as json\n",
    "            raw_data = json.loads(data)\n",
    "\n",
    "            #insert data just collected into MySQL my_database\n",
    "            self.populate_table(raw_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(traceback.format_exc())\n",
    "            # Logs the error appropriately. \n",
    "            \n",
    "\n",
    "# todo : create the tables on init\n",
    "    def populate_table(\n",
    "        self, raw_data\n",
    "    ):\n",
    "        \"\"\"Populate a given table witht he Twitter collected data\n",
    "\n",
    "        Args:\n",
    "            raw_data (json) : storing raw data for further usage\n",
    "        \"\"\"\n",
    "        engine = create_engine(self.database)\n",
    "\n",
    "        # Create connection\n",
    "        conn = engine.connect()\n",
    "        meta = MetaData()\n",
    "        \n",
    "        #get table\n",
    "        raw_tweet = Table('raw_tweet', meta, autoload=True, autoload_with=engine)\n",
    "        \n",
    "        # Begin transaction\n",
    "        trans = conn.begin()\n",
    "        \n",
    "        ins = raw_tweet.insert().values(rawtweet=raw_data)\n",
    "\n",
    "        #actual content of request\n",
    "        conn.execute(ins)\n",
    "\n",
    "        try:\n",
    "            trans.commit()\n",
    "\n",
    "        except mysql.Error as e:\n",
    "            print(e)\n",
    "            trans.rollback()\n",
    "\n",
    "        # Close connection\n",
    "        conn.close()\n",
    "        print(f\"Tweet colleted\")\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweepy_listener = TwitterListener()\n",
    "tweepy_stream = tweepy.Stream(auth = api.auth, listener=tweepy_listener)\n",
    "results = tweepy_stream.filter(track=['Minecraft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "duration": 0.076122,
   "end_time": "2020-01-10T05:38:05.047547",
   "environment_variables": {},
   "exception": null,
   "input_path": "/usr/local/airflow/notebooks/raw_twitter.ipynb",
   "output_path": "/usr/local/airflow/notebooks/out-twitter-.ipynb",
   "parameters": {
    "hashtag": "minecraft"
   },
   "start_time": "2020-01-10T05:38:04.971425",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}